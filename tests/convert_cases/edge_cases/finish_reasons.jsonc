{
  "description": "Test OpenAI finish_reason to Claude stop_reason conversion",
  
  "claude_request": {
    "model": "claude-3-haiku-20240307",
    "max_tokens": 10, // Very small limit to test max_tokens finish
    "messages": [
      {
        "role": "user",
        "content": "Write a very long story about programming."
      }
    ]
  },
  
  "expected_openai_request": {
    "model": "gpt-4o-mini",
    "messages": [
      {
        "role": "user",
        "content": "Write a very long story about programming."
      }
    ],
    "max_tokens": 10,
    "stream": false
  },
  
  "openai_response": {
    "id": "chatcmpl-length123",
    "object": "chat.completion",
    "created": 1677652288,
    "model": "gpt-4o-mini",
    "choices": [
      {
        "index": 0,
        "message": {
          "role": "assistant",
          "content": "Once upon a time, in a"
        },
        "finish_reason": "length" // Hit max_tokens limit
      }
    ],
    "usage": {
      "prompt_tokens": 15,
      "completion_tokens": 10,
      "total_tokens": 25
    }
  },
  
  "expected_claude_response": {
    "id": "chatcmpl-length123",
    "type": "message",
    "role": "assistant",
    "model": "claude-3-haiku-20240307",
    "content": [
      {
        "type": "text",
        "text": "Once upon a time, in a"
      }
    ],
    "stop_reason": "max_tokens", // finish_reason "length" -> stop_reason "max_tokens"
    "usage": {
      "input_tokens": 15,
      "output_tokens": 10
    }
  }
}