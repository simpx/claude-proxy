"""
æ•°æ®é©±åŠ¨çš„æ ¼å¼è½¬æ¢æµ‹è¯•
ä½¿ç”¨JSONCæ¡ˆä¾‹æ–‡ä»¶æµ‹è¯•Claudeåˆ°OpenAIçš„APIæ ¼å¼è½¬æ¢
"""

import pytest
import sys
import os
from pathlib import Path
from unittest.mock import patch

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.claude_proxy.providers.openai import OpenAIProvider
from src.claude_proxy.models.claude import ClaudeMessagesRequest, ClaudeMessage
from src.claude_proxy.config import get_settings
from tests.conversion_runner import ConversionCaseLoader, ConversionTestValidator


class TestConvertCases:
    """åŸºäºæ•°æ®é©±åŠ¨çš„æ ¼å¼è½¬æ¢æµ‹è¯•"""
    
    # é¢„è®¾çš„æµ‹è¯•ç¯å¢ƒå˜é‡
    TEST_ENV_VARS = {
        'OPENAI_API_KEY': 'sk-test-key-12345',
        'OPENAI_BASE_URL': 'https://api.openai.com/v1',
        'CLAUDE_PROXY_BIG_MODEL': 'gpt-4o',
        'CLAUDE_PROXY_SMALL_MODEL': 'gpt-4o-mini',
        'CLAUDE_PROXY_LOG_LEVEL': 'INFO',
        'CLAUDE_PROXY_HOST': '0.0.0.0',
        'CLAUDE_PROXY_PORT': '8080',
    }
    
    @classmethod
    def setup_class(cls):
        """æµ‹è¯•ç±»åˆå§‹åŒ–"""
        cls.loader = ConversionCaseLoader()
        cls.validator = ConversionTestValidator()
        cls.cases = cls.loader.load_all_cases()
        
        print(f"\nğŸ§ª Loaded {len(cls.cases)} conversion test cases")
    
    @pytest.mark.parametrize("case", [
        pytest.param(case, id=f"{case.category}::{case.file_name}") 
        for case in ConversionCaseLoader().load_all_cases()
        if (case.test_config.get('test_request_conversion', True) 
            and case.claude_request 
            and case.expected_openai_request)
    ])
    def test_convert(self, case):
        """æµ‹è¯•Claudeè¯·æ±‚åˆ°OpenAIè¯·æ±‚çš„è½¬æ¢"""
        # è®¾ç½®æµ‹è¯•ç¯å¢ƒå˜é‡ï¼Œå¯è¢«case.envè¦†ç›–
        test_env = self.TEST_ENV_VARS.copy()
        if hasattr(case, 'env') and case.env:
            test_env.update(case.env)
        
        with patch.dict(os.environ, test_env, clear=False):
            # æ¸…é™¤ç¼“å­˜çš„è®¾ç½®å¹¶é‡æ–°åŠ è½½é…ç½®
            import src.claude_proxy.config as config_module
            config_module._settings = None
            settings = config_module.get_settings()
            
            # åˆ›å»ºOpenAI providerå®ä¾‹
            provider = OpenAIProvider(
                api_key="test-key",
                base_url="https://api.openai.com/v1",
                timeout=30
            )
            
            # å°†Claudeè¯·æ±‚è½¬æ¢ä¸ºPydanticæ¨¡å‹
            claude_request = ClaudeMessagesRequest(**case.claude_request)
            
            # æ‰§è¡Œè½¬æ¢
            actual_openai_request = provider.convert_request(claude_request)
            
            # éªŒè¯è½¬æ¢ç»“æœ
            is_valid, errors = self.validator.validate_request_conversion(
                case.claude_request,
                actual_openai_request,
                case.expected_openai_request
            )
            
            # æ–­è¨€éªŒè¯ç»“æœ
            if not is_valid:
                error_msg = f"Request conversion failed for case '{case.file_name}':\n"
                for error in errors:
                    error_msg += f"  - {error}\n"
                error_msg += f"\nExpected: {case.expected_openai_request}\n"
                error_msg += f"Actual: {actual_openai_request}\n"
                error_msg += f"Case file: {case.file_path}"
                
                pytest.fail(error_msg)
    
    @pytest.mark.parametrize("case", [
        pytest.param(case, id=f"{case.category}::{case.file_name}")
        for case in ConversionCaseLoader().load_all_cases()
        if (case.test_config.get('test_response_conversion', True) 
            and case.openai_response 
            and case.expected_claude_response)
    ])
    def test_response_conversion(self, case):
        """æµ‹è¯•OpenAIå“åº”åˆ°Claudeå“åº”çš„è½¬æ¢"""
        # è®¾ç½®æµ‹è¯•ç¯å¢ƒå˜é‡ï¼Œå¯è¢«case.envè¦†ç›–
        test_env = self.TEST_ENV_VARS.copy()
        if hasattr(case, 'env') and case.env:
            test_env.update(case.env)
        
        with patch.dict(os.environ, test_env, clear=False):
            # æ¸…é™¤ç¼“å­˜çš„è®¾ç½®å¹¶é‡æ–°åŠ è½½é…ç½®
            import src.claude_proxy.config as config_module
            config_module._settings = None
            settings = config_module.get_settings()
            
            # åˆ›å»ºOpenAI providerå®ä¾‹
            provider = OpenAIProvider(
                api_key="test-key",
                base_url="https://api.openai.com/v1",
                timeout=30
            )
            
            # åˆ›å»ºåŸå§‹Claudeè¯·æ±‚ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
            claude_request = None
            if case.claude_request:
                claude_request = ClaudeMessagesRequest(**case.claude_request)
            
            # æ‰§è¡Œå“åº”è½¬æ¢
            actual_claude_response = provider.convert_response(
                case.openai_response,
                claude_request
            )
        
        # éªŒè¯è½¬æ¢ç»“æœ
        is_valid, errors = self.validator.validate_response_conversion(
            case.openai_response,
            actual_claude_response.model_dump(),
            case.expected_claude_response
        )
        
        # æ–­è¨€éªŒè¯ç»“æœ
        if not is_valid:
            error_msg = f"Response conversion failed for case '{case.file_name}':\n"
            for error in errors:
                error_msg += f"  - {error}\n"
            error_msg += f"\nExpected: {case.expected_claude_response}\n"
            error_msg += f"Actual: {actual_claude_response.model_dump()}\n"
            error_msg += f"Case file: {case.file_path}"
            
            pytest.fail(error_msg)
    
    @pytest.mark.parametrize("case", [
        pytest.param(case, id=f"{case.category}::{case.file_name}")
        for case in ConversionCaseLoader().load_all_cases()
        if (case.test_config.get('test_model_mapping', True) 
            and case.claude_request 
            and case.expected_openai_request)
    ])
    def test_model_mapping(self, case):
        """æµ‹è¯•æ¨¡å‹æ˜ å°„æ˜¯å¦æ­£ç¡®"""
        # è®¾ç½®æµ‹è¯•ç¯å¢ƒå˜é‡ï¼Œå¯è¢«case.envè¦†ç›–
        test_env = self.TEST_ENV_VARS.copy()
        if hasattr(case, 'env') and case.env:
            test_env.update(case.env)
        
        with patch.dict(os.environ, test_env, clear=False):
            # æ¸…é™¤ç¼“å­˜çš„è®¾ç½®å¹¶é‡æ–°åŠ è½½é…ç½®
            import src.claude_proxy.config as config_module
            config_module._settings = None
            
            from src.claude_proxy.config import map_claude_model
            
            claude_model = case.claude_request['model']
            expected_openai_model = case.expected_openai_request['model']
            actual_mapped_model = map_claude_model(claude_model)
        
        # éªŒè¯æ¨¡å‹æ˜ å°„
        is_valid, errors = self.validator.validate_model_mapping(
            claude_model,
            actual_mapped_model, 
            expected_openai_model
        )
        
        if not is_valid:
            error_msg = f"Model mapping failed for case '{case.file_name}':\n"
            for error in errors:
                error_msg += f"  - {error}\n"
            error_msg += f"Case file: {case.file_path}"
            
            pytest.fail(error_msg)
    
    @pytest.mark.parametrize("case", [
        pytest.param(case, id=f"{case.category}::{case.file_name}")
        for case in ConversionCaseLoader().load_all_cases()
        if (case.test_config.get('test_streaming_conversion', False)
            and case.openai_streaming_response
            and case.expected_claude_streaming_response)
    ])
    def test_streaming_conversion(self, case):
        """æµ‹è¯•æµå¼å“åº”è½¬æ¢"""
        # è¿™æ˜¯ä¸€ä¸ªæ›´å¤æ‚çš„æµ‹è¯•ï¼Œéœ€è¦æ¨¡æ‹ŸSSEæµ
        # æš‚æ—¶æ ‡è®°ä¸ºTODOï¼Œéœ€è¦å®ç°æµå¼è½¬æ¢é€»è¾‘åå†å®Œæˆ
        pytest.skip("Streaming conversion test not implemented yet")
    
    def test_case_file_integrity(self):
        """æµ‹è¯•æ¡ˆä¾‹æ–‡ä»¶çš„å®Œæ•´æ€§"""
        errors = []
        
        for case in self.cases:
            # æ£€æŸ¥å¿…éœ€å­—æ®µ
            if not case.file_name:
                errors.append(f"Case in {case.file_path} missing file_name")
            
            # æ£€æŸ¥è‡³å°‘æœ‰ä¸€ç»„æœ‰æ•ˆçš„æµ‹è¯•æ•°æ®
            has_request_test = case.claude_request and case.expected_openai_request
            has_response_test = case.openai_response and case.expected_claude_response
            
            if not (has_request_test or has_response_test):
                errors.append(f"Case '{case.file_name}' missing complete test data")
                continue
                
            # æ£€æŸ¥Claudeè¯·æ±‚å¿…éœ€å­—æ®µï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            if case.claude_request:
                if 'model' not in case.claude_request:
                    errors.append(f"Case '{case.file_name}' claude_request missing model")
                    
                if 'max_tokens' not in case.claude_request:
                    errors.append(f"Case '{case.file_name}' claude_request missing max_tokens")
                    
                if 'messages' not in case.claude_request:
                    errors.append(f"Case '{case.file_name}' claude_request missing messages")
        
        if errors:
            error_msg = "Case file integrity check failed:\n"
            for error in errors:
                error_msg += f"  - {error}\n"
            pytest.fail(error_msg)
    
    def test_categories_and_tags(self):
        """æµ‹è¯•æ¡ˆä¾‹çš„åˆ†ç±»å’Œæ ‡ç­¾"""
        categories = set()
        all_tags = set()
        
        for case in self.cases:
            categories.add(case.category)
            all_tags.update(case.tags)
        
        # ç¡®ä¿æœ‰åŸºæœ¬çš„åˆ†ç±»
        expected_categories = {'basic', 'advanced'}
        missing_categories = expected_categories - categories
        
        if missing_categories:
            pytest.fail(f"Missing expected categories: {missing_categories}")
        
        # ç¡®ä¿æœ‰åŸºæœ¬çš„æ ‡ç­¾ï¼ˆå¯é€‰æ£€æŸ¥ï¼Œå› ä¸ºæˆ‘ä»¬ç§»é™¤äº†å¤§å¤šæ•°æ ‡ç­¾ï¼‰
        print(f"Found tags: {all_tags}")  # ä»…ç”¨äºè°ƒè¯•
        # ä¸å¼ºåˆ¶è¦æ±‚ç‰¹å®šæ ‡ç­¾ï¼Œå› ä¸ºæˆ‘ä»¬ç®€åŒ–äº†æ ‡ç­¾ç³»ç»Ÿ
    
    @classmethod
    def teardown_class(cls):
        """æµ‹è¯•ç±»æ¸…ç†"""
        print(f"\nâœ… Completed testing {len(cls.cases)} conversion cases")


if __name__ == "__main__":
    # ç›´æ¥è¿è¡Œæµ‹è¯•
    pytest.main([__file__, "-v", "--tb=short"])